{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports U.S county names. \n",
    "Input name should have county tag at the end (example Tippecanoe county, clay county). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "import fnmatch\n",
    "gc = geonamescache.GeonamesCache()\n",
    "co = gc.get_us_counties()\n",
    "counties = []\n",
    "for i in co:\n",
    "    counties.append(i['name'].upper())\n",
    "    if i['name'].find(' County') != -1:\n",
    "        counties.append(i['name'].replace(' County','').upper())\n",
    "\n",
    "def county_chk(strn):\n",
    "    '''Function to detect the validity of the county name. Uses geonamescache library'''\n",
    "    if strn.upper() not in counties:\n",
    "        return 'Not valid'\n",
    "    else:\n",
    "        return 'Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports city names across the globe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "c = gc.get_cities()\n",
    "cities = [c[key]['name'] for key in list(c.keys())]\n",
    "cities = list(map(lambda x:x.upper(), cities))\n",
    "cities = [x for x in cities if str(x) != 'NAN']\n",
    "\n",
    "def city_chk(strn):\n",
    "    '''Function to detect the validity of the city name. Uses geonamescache library'''\n",
    "    if strn.upper() in cities:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports U.S state names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "st = gc.get_us_states()\n",
    "stcode = []\n",
    "states = []\n",
    "for i in st:\n",
    "    stcode.append(st[i]['code'])\n",
    "    states.append(st[i]['name'].upper())\n",
    "\n",
    "def state_chk(strn):\n",
    "    '''Function to detect the validity of the state name. Uses geonamescache library'''\n",
    "    chk = 0\n",
    "    if strn.upper() in states or strn.upper() in stcode:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports country names across the globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "cntrs = list(pycountry.countries)\n",
    "c_name = []\n",
    "official_name = []\n",
    "alpha_2 = []\n",
    "alpha_3 = []\n",
    "for i in cntrs:\n",
    "    c_name.append(i.name.upper())\n",
    "    if i.name.find(',')!=-1:\n",
    "        c_name.append((i.name[i.name.find(',')+2:]+' '+i.name[:i.name.find(',')]).upper())\n",
    "        for j in ('IRAN','RUSSIA','SOUTH KOREA','VIETNAM','BOLIVIA','TAIWAN','UK','SYRIA','VENEZUELA'):\n",
    "            c_name.append(j)\n",
    "    try:\n",
    "        official_name.append(i.official_name.upper())\n",
    "    except:\n",
    "        pass\n",
    "    alpha_2.append(i.alpha_2)\n",
    "    alpha_3.append(i.alpha_3)\n",
    "    \n",
    "\n",
    "def country_chk(strn):\n",
    "    '''Function to detect the validity of the country name. Uses pycountry library'''\n",
    "    chk = 0\n",
    "    if strn.upper() in c_name or strn.upper() in official_name or strn.upper() in alpha_2 or strn.upper() in alpha_3:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Currency_US Dollar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satisfying Conditions:\n",
    "\n",
    "1. Format: Currency(space optional)NNNN.DD(upto 2 decimals)\n",
    "2. Currency : USD|usd|EUR|EURO|euro|eur|£|JPY|¥|CNY|GBP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_chk(amount):\n",
    "    '''Function to detect the validity of the US Cuurency. Uses regex library'''\n",
    "    import re\n",
    "    regex = re.compile(r'^(\\$|USD|usd|EUR|EURO|euro|eur|£|JPY|¥|CNY|GBP)\\s?(\\d*(\\d\\.?|\\.\\d{1,2}))$')\n",
    "    result = regex.match(amount)\n",
    "    if result:\n",
    "        return('Valid')\n",
    "    else:\n",
    "        return('Not Valid')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "print(currency_chk('USD 1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Phone Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supports following formats\n",
    "1. 000-000-0000\n",
    "2. 000 000 0000\n",
    "3. 000.000.0000\n",
    "4. (000)0000000\n",
    "5. 000-0000\n",
    "6. 000 0000\n",
    "7. 000.0000\n",
    "8. 0000000\n",
    "9. 0000000000\n",
    "\n",
    "Maximum of 12 digits is allowed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_chk(number):\n",
    "    '''Function to detect the phone numbers in US. Supports home/landline phone numbers and mobile numbers.\n",
    "        Uses regex library'''\n",
    "    if len(number)<=12 and len(number)>=6:\n",
    "        import re\n",
    "        regex=re.compile(r'^\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}')\n",
    "        result = regex.match(number)\n",
    "        if result:\n",
    "            return 'Valid'\n",
    "        else:\n",
    "            return 'Not Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Valid'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_chk('848-220-4469')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Credit Card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Luhn Algorithm to detct the credit card detections\n",
    "\n",
    " https://en.wikipedia.org/wiki/Payment_card_number\n",
    " \n",
    " https://en.wikipedia.org/wiki/Luhn_algorithm\n",
    " \n",
    " https://www.geeksforgeeks.org/luhn-algorithm/\n",
    " \n",
    " Number of digits allowed : 13-19\n",
    "        \n",
    "Working Credit Cards under this Algo: \n",
    "1. AMEX\n",
    "2. Bankcard\n",
    "3. Diners Club enRoue\n",
    "4. Discover Card\n",
    "5. RuPay\n",
    "6. InterPayment\n",
    "7. JCB\n",
    "8. Laser\n",
    "9. Maestro\n",
    "10. Dankort\n",
    "11. MIR\n",
    "12. NPS Pridnestrovie\n",
    "13. Mastercard\n",
    "14. Solo\n",
    "15. Switch\n",
    "16. Troy\n",
    "17. Visa\n",
    "18. UATP\n",
    "19. Verve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_chk(card_number):\n",
    "    '''Function to detect whether credit card is valid or not by its card number. Dev. by using Luhn algo'''\n",
    "    if len(card_number)>=13 and len(card_number)<=19:\n",
    "        try:\n",
    "            cc_list=[int(d) for d in str(card_number)]\n",
    "            odd_digits = cc_list[-1::-2]\n",
    "            #print(odd_digits)\n",
    "            even_digits = cc_list[-2::-2]\n",
    "            #print(even_digits)\n",
    "            cc_digits_sum = 0\n",
    "            cc_digits_sum += sum(odd_digits)\n",
    "            for d in even_digits:\n",
    "                d*=2\n",
    "                if d > 9:\n",
    "                    d= d-9 \n",
    "                cc_digits_sum=cc_digits_sum + d\n",
    "            if cc_digits_sum % 10==0:\n",
    "                return 'Valid'\n",
    "            else:\n",
    "                return 'Not Valid'\n",
    "        except:\n",
    "            return 'Not Valid'\n",
    "    else:\n",
    "        return 'Not Valid'\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Valid'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_chk('848 220  4469')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Mail ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mail ID starting character should be aplhamnumeric. \n",
    "Should have 2 or 3 characters at the end after '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_chk(val):\n",
    "    \n",
    "    '''Function to detect the validity email. Uses regex library'''\n",
    "    import re\n",
    "    regex = '^\\w+([\\.-]?\\w+)*@\\w+([\\.-]?\\w+)*(\\.\\w{2,3})+$'\n",
    "    c=0\n",
    "    if(re.search(regex,val)):  \n",
    "         return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL should start with http:// or https://, can have any alphanumeric domain name and must end with two or more characters after the '.'\n",
    "It also incorporates URLs with IP or server addresses like \"http://localhost:8889/notebooks/Functions_Data%20Profiling.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_chk(val):\n",
    "    \n",
    "    '''Function to detect the validity email. Uses regex library'''\n",
    "    import re\n",
    "    a=0\n",
    "    regex = re.compile(\n",
    "            r'^(?:http|ftp)s?://' # http:// or https://\n",
    "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "            r'localhost|' #localhost...\n",
    "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "            r'(?::\\d+)?' # optional port\n",
    "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "\n",
    "    if (re.match(regex, val) is not None) == True:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Works with Jan, jan, January, 01, 1 formats. \n",
    "2. If the input is using correct word for the month, irrespective of the lower, upper cases it will read ( Jan, JAn, jANUaRy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_chk(string):\n",
    "    import re\n",
    "    regex = re.compile(r'(\\b((0?[1-9]|1[012])$|jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|(nov|dec)(?:ember)?)\\D?)')\n",
    "    string=string.lower()\n",
    "    result = regex.match(string)\n",
    "    if result:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works with\n",
    "1. Positive and negative sign for the temperature\n",
    "2. After decimal 2 digits only\n",
    "3. Temperature symbol can be [CcFf]\n",
    "4. Space or no-space between ineteger and the temp (CcFf) symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_chk(string):\n",
    "    import re\n",
    "    #regex=re.compile(r\"([+-]?(\\d*(\\d\\.?|\\.\\d))\\s?°?([CcFf]))\")\n",
    "    #regex=re.compile(r\"([+-]?((\\d*(\\d\\.?|\\.\\d{1,2}))\\s?°?(\\b c|\\b C|\\b F|\\b f){1}))\")\n",
    "    regex=re.compile(r\"([+-]?((\\d*(\\d\\.?|\\.\\d{1,2}))\\s?°?(?i)(\\W|^)(C|c|F|F)(\\W|$)))\")\n",
    "    result=regex.match(string)\n",
    "    if result:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_chk(string):\n",
    "    import re\n",
    "    #regex=re.compile(r\"([+-]?(\\d*(\\d\\.?|\\.\\d))\\s?°?([CcFf]))\")\n",
    "    regex=re.compile(r\"((\\d*(\\d\\.?|\\.\\d{1,2}))\\s?(?i)(\\W|^)(KMS|km|miles|mile|INCH|M|feet|ft)(\\W|$))\")\n",
    "    result=regex.match(string)\n",
    "    if result:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def date_chk(date_time_str):\n",
    "    chk = 0\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y-%m-%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y-%d-%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y-%d-%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y/%m/%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y/%m/%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y/%d/%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y/%d/%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m-%d-%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m-%d-%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d-%m-%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d-%m-%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m/%d/%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m/%d/%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d/%m/%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d/%m/%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if chk == 1:\n",
    "        return 'Valid'\n",
    "\n",
    "    else:\n",
    "        return 'Not Valid'\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_chk(date_time_str):\n",
    "    chk = 0\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%H:%M')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%H:%M:%S')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%H:%M:%S.%f')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "    if chk == 1:\n",
    "        return 'Valid'\n",
    "\n",
    "    else:\n",
    "        return 'Not Valid'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the csv file, checking the column characteristic and assigning the accuracy score:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the FileS List: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "path ='/Users/sagarkurada/Documents/Courses/Spring-3/Data Profiling/Data/' # use your path, replace the last backslash with filename to run for a single file\n",
    "\n",
    "csv = glob.glob(path + \"*.csv\")\n",
    "\n",
    "lst = dict()\n",
    "\n",
    "for filename in csv:\n",
    "    #print(\"vammo\",filename)\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    lst[filename] = df\n",
    "\n",
    "#print(lst)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data):\n",
    "    '''Random sampling of data'''\n",
    "    if data.shape[0] > 300:\n",
    "        return data.sample(n=300, random_state=1)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of entity columns to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "funclist = [county_chk,city_chk,state_chk,country_chk,currency_chk,phone_chk,credit_card_chk,email_chk,url_chk,date_chk,time_chk,distance_chk,temperature_chk,month_chk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Score Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cscore(data):\n",
    "    '''Function to calculate the confidence score for each column'''\n",
    "    print('\\nCONFIDENCE SCORES:\\n ')\n",
    "    data = sample(data)\n",
    "    data_dict = data.to_dict()\n",
    "    for i in data_dict.keys():\n",
    "        print('Column-',i,': ')\n",
    "        for j in funclist:\n",
    "            d2 = dict((k,j(str(v))) for k, v in data_dict[i].items())\n",
    "            d3= {k:(1 if v=='Valid' else 0 ) for (k,v) in d2.items()}\n",
    "            a=[v for v in d3.values()]\n",
    "            accuracy=round((sum(a)/len(a))*100,2)\n",
    "            if accuracy != 0:\n",
    "                print('\\t',str(j)[9:str(j).find('at ')-5],': ',str(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/sagarkurada/Documents/Courses/Spring-3/Data Profiling/Data/Credit_Card_Number.csv\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      " \n",
      "Column- Credit _Card_Number : \n",
      "\t  credit_card :  5.88\n",
      "File: /Users/sagarkurada/Documents/Courses/Spring-3/Data Profiling/Data/hotel_bookings.csv\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      " \n",
      "Column- hotel : \n",
      "Column- is_canceled : \n",
      "\t  month :  39.33\n",
      "Column- lead_time : \n",
      "\t  month :  11.67\n",
      "Column- arrival_date_year : \n",
      "Column- arrival_date_month : \n",
      "\t  city :  8.0\n",
      "\t  month :  100.0\n",
      "Column- arrival_date_week_number : \n",
      "\t  month :  15.67\n",
      "Column- arrival_date_day_of_month : \n",
      "\t  month :  43.33\n",
      "Column- stays_in_weekend_nights : \n",
      "\t  month :  54.0\n",
      "Column- stays_in_week_nights : \n",
      "\t  month :  96.67\n",
      "Column- adults : \n",
      "\t  month :  99.67\n",
      "Column- children : \n",
      "Column- babies : \n",
      "Column- meal : \n",
      "\t  state :  7.0\n",
      "\t  country :  87.0\n",
      "Column- country : \n",
      "\t  city :  1.33\n",
      "\t  country :  99.67\n",
      "Column- market_segment : \n",
      "Column- distribution_channel : \n",
      "Column- is_repeated_guest : \n",
      "\t  month :  3.0\n",
      "Column- previous_cancellations : \n",
      "\t  month :  3.33\n",
      "Column- previous_bookings_not_canceled : \n",
      "\t  month :  2.67\n",
      "Column- reserved_room_type : \n",
      "Column- assigned_room_type : \n",
      "Column- booking_changes : \n",
      "\t  month :  13.67\n",
      "Column- deposit_type : \n",
      "Column- agent : \n",
      "Column- company : \n",
      "Column- days_in_waiting_list : \n",
      "\t  month :  0.33\n",
      "Column- customer_type : \n",
      "Column- adr : \n",
      "Column- required_car_parking_spaces : \n",
      "\t  month :  5.0\n",
      "Column- total_of_special_requests : \n",
      "\t  month :  38.33\n",
      "Column- reservation_status : \n",
      "Column- reservation_status_date : \n",
      "\t  date :  100.0\n",
      "File: /Users/sagarkurada/Documents/Courses/Spring-3/Data Profiling/Data/avocado.csv\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      " \n",
      "Column- Unnamed: 0 : \n",
      "\t  month :  26.33\n",
      "Column- Date : \n",
      "\t  date :  100.0\n",
      "Column- AveragePrice : \n",
      "Column- Total Volume : \n",
      "\t  phone :  13.0\n",
      "Column- 4046 : \n",
      "\t  phone :  6.33\n",
      "Column- 4225 : \n",
      "\t  phone :  8.0\n",
      "Column- 4770 : \n",
      "\t  phone :  0.67\n",
      "Column- Total Bags : \n",
      "\t  phone :  6.67\n",
      "Column- Small Bags : \n",
      "\t  phone :  4.0\n",
      "Column- Large Bags : \n",
      "\t  phone :  2.0\n",
      "Column- XLarge Bags : \n",
      "Column- type : \n",
      "Column- year : \n",
      "Column- region : \n",
      "\t  county :  19.67\n",
      "\t  city :  46.33\n",
      "\t  state :  2.0\n",
      "File: /Users/sagarkurada/Documents/Courses/Spring-3/Data Profiling/Data/data.csv\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      " \n",
      "Column- Country : \n",
      "\t  city :  4.33\n",
      "\t  state :  0.33\n",
      "\t  country :  80.33\n",
      "Column- State : \n",
      "\t  county :  28.0\n",
      "\t  city :  13.0\n",
      "\t  state :  80.33\n",
      "\t  country :  3.0\n",
      "\t  month :  1.33\n",
      "Column- City : \n",
      "\t  county :  2.33\n",
      "\t  city :  66.0\n",
      "\t  state :  0.33\n",
      "\t  country :  0.33\n",
      "\t  month :  0.67\n",
      "Column- County : \n",
      "\t  county :  80.33\n",
      "\t  city :  30.67\n",
      "\t  state :  2.0\n",
      "\t  month :  2.67\n",
      "Column- Phone Number : \n",
      "\t  phone :  81.67\n",
      "Column- Credit Card : \n",
      "Column- Email ID : \n",
      "\t  email :  81.67\n",
      "\t  month :  2.0\n",
      "Column- URL : \n",
      "\t  url :  81.67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for key in lst:\n",
    "    print('File:',key)\n",
    "    cscore(lst[key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(data):\n",
    "    rw = data.shape[0]\n",
    "    print('Rows: ',str(rw))\n",
    "    print('Columns: ',str(data.shape[1]),'\\n')\n",
    "    pk = []\n",
    "    mis = []\n",
    "    for col in data:\n",
    "        try:\n",
    "            pd.to_numeric(data[col])\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "        print(col,':-')\n",
    "        u = data[col].nunique()\n",
    "        print('Unique Value Count:',u)\n",
    "        if u == rw:\n",
    "            pk.append(col)\n",
    "        n = data[col].size - data[col].count()\n",
    "        print('Null Count:',n)\n",
    "        if n != 0:\n",
    "            mis.append(col)\n",
    "        freq = data[col].value_counts()\n",
    "        print('Top Three Frequency Values:')\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                val = freq[i]\n",
    "            except:\n",
    "                break\n",
    "            if val == 1:\n",
    "                if i == 0:\n",
    "                    print('N/A')\n",
    "                break\n",
    "            print('\\t',freq.keys()[i],':',val) \n",
    "        print('')\n",
    "    print ('Possible Primary Key(s):',pk)\n",
    "    print ('Columns with missing data:',mis,'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- avocado.csv ----------------------\n",
      "DATA SUMMARY:\n",
      "\n",
      "Rows:  18249\n",
      "Columns:  14 \n",
      "\n",
      "Date :-\n",
      "Unique Value Count: 169\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t 2017-12-31 : 108\n",
      "\t 2017-10-08 : 108\n",
      "\t 2015-10-04 : 108\n",
      "\n",
      "type :-\n",
      "Unique Value Count: 2\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t conventional : 9126\n",
      "\t organic : 9123\n",
      "\n",
      "region :-\n",
      "Unique Value Count: 54\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t DallasFtWorth : 338\n",
      "\t Albany : 338\n",
      "\t Midsouth : 338\n",
      "\n",
      "Possible Primary Key(s): []\n",
      "Columns with missing data: [] \n",
      "\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      "\n",
      "Unnamed: 0 : \n",
      "\t  credit_card :  9.33\n",
      "\t  month :  26.33\n",
      "Date : \n",
      "\t  date :  100.0\n",
      "AveragePrice : \n",
      "Total Volume : \n",
      "\t  phone :  13.0\n",
      "4046 : \n",
      "\t  phone :  6.33\n",
      "4225 : \n",
      "\t  phone :  8.0\n",
      "4770 : \n",
      "\t  phone :  0.67\n",
      "Total Bags : \n",
      "\t  phone :  6.67\n",
      "Small Bags : \n",
      "\t  phone :  4.0\n",
      "Large Bags : \n",
      "\t  phone :  2.0\n",
      "XLarge Bags : \n",
      "type : \n",
      "year : \n",
      "region : \n",
      "\t  county :  19.67\n",
      "\t  city :  46.33\n",
      "\t  state :  2.0\n",
      "---------------------- data.csv ----------------------\n",
      "DATA SUMMARY:\n",
      "\n",
      "Rows:  250\n",
      "Columns:  8 \n",
      "\n",
      "Country :-\n",
      "Unique Value Count: 68\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t China : 74\n",
      "\t India : 19\n",
      "\t Brazil : 12\n",
      "\n",
      "State :-\n",
      "Unique Value Count: 52\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t Oregon : 5\n",
      "\t Michigan : 5\n",
      "\t Hawaii : 5\n",
      "\n",
      "City :-\n",
      "Unique Value Count: 247\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t Semarang : 2\n",
      "\t Hyderabad : 2\n",
      "\t BUDAPEST : 2\n",
      "\n",
      "County :-\n",
      "Unique Value Count: 230\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t Jackson : 2\n",
      "\t Montgomery : 2\n",
      "\t Santa Cruz : 2\n",
      "\n",
      "Phone Number :-\n",
      "Unique Value Count: 120\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t 907-758-6560 : 3\n",
      "\t 908-272-1436 : 3\n",
      "\t 916-712-5188 : 3\n",
      "\n",
      "Email ID :-\n",
      "Unique Value Count: 248\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t aracne@yahoo.ca : 2\n",
      "\t ozawa@mac.com : 2\n",
      "\n",
      "URL :-\n",
      "Unique Value Count: 181\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t https://www.example.com/ : 15\n",
      "\t http://www.example.com/ : 15\n",
      "\t https://example.com/ : 13\n",
      "\n",
      "Possible Primary Key(s): []\n",
      "Columns with missing data: [] \n",
      "\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      "\n",
      "Country : \n",
      "\t  city :  5.2\n",
      "\t  state :  0.4\n",
      "\t  country :  98.4\n",
      "State : \n",
      "\t  county :  34.4\n",
      "\t  city :  16.4\n",
      "\t  state :  98.4\n",
      "\t  country :  3.6\n",
      "\t  month :  2.0\n",
      "City : \n",
      "\t  county :  2.8\n",
      "\t  city :  80.8\n",
      "\t  state :  0.4\n",
      "\t  country :  0.4\n",
      "\t  month :  0.8\n",
      "County : \n",
      "\t  county :  98.4\n",
      "\t  city :  36.8\n",
      "\t  state :  2.4\n",
      "\t  month :  3.2\n",
      "Phone Number : \n",
      "\t  phone :  100.0\n",
      "Credit Card : \n",
      "\t  phone :  100.0\n",
      "Email ID : \n",
      "\t  email :  100.0\n",
      "\t  month :  2.4\n",
      "URL : \n",
      "\t  url :  100.0\n",
      "---------------------- hotel_bookings.csv ----------------------\n",
      "DATA SUMMARY:\n",
      "\n",
      "Rows:  119390\n",
      "Columns:  32 \n",
      "\n",
      "hotel :-\n",
      "Unique Value Count: 2\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t City Hotel : 79330\n",
      "\t Resort Hotel : 40060\n",
      "\n",
      "arrival_date_month :-\n",
      "Unique Value Count: 12\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t August : 13877\n",
      "\t July : 12661\n",
      "\t May : 11791\n",
      "\n",
      "meal :-\n",
      "Unique Value Count: 5\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t BB : 92310\n",
      "\t HB : 14463\n",
      "\t SC : 10650\n",
      "\n",
      "country :-\n",
      "Unique Value Count: 177\n",
      "Null Count: 488\n",
      "Top Three Frequency Values:\n",
      "\t PRT : 48590\n",
      "\t GBR : 12129\n",
      "\t FRA : 10415\n",
      "\n",
      "market_segment :-\n",
      "Unique Value Count: 8\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t Online TA : 56477\n",
      "\t Offline TA/TO : 24219\n",
      "\t Groups : 19811\n",
      "\n",
      "distribution_channel :-\n",
      "Unique Value Count: 5\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t TA/TO : 97870\n",
      "\t Direct : 14645\n",
      "\t Corporate : 6677\n",
      "\n",
      "reserved_room_type :-\n",
      "Unique Value Count: 10\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t A : 85994\n",
      "\t D : 19201\n",
      "\t E : 6535\n",
      "\n",
      "assigned_room_type :-\n",
      "Unique Value Count: 12\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t A : 74053\n",
      "\t D : 25322\n",
      "\t E : 7806\n",
      "\n",
      "deposit_type :-\n",
      "Unique Value Count: 3\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t No Deposit : 104641\n",
      "\t Non Refund : 14587\n",
      "\t Refundable : 162\n",
      "\n",
      "customer_type :-\n",
      "Unique Value Count: 4\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t Transient : 89613\n",
      "\t Transient-Party : 25124\n",
      "\t Contract : 4076\n",
      "\n",
      "reservation_status :-\n",
      "Unique Value Count: 3\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t Check-Out : 75166\n",
      "\t Canceled : 43017\n",
      "\t No-Show : 1207\n",
      "\n",
      "reservation_status_date :-\n",
      "Unique Value Count: 926\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "\t 2015-10-21 : 1461\n",
      "\t 2015-07-06 : 805\n",
      "\t 2016-11-25 : 790\n",
      "\n",
      "Possible Primary Key(s): []\n",
      "Columns with missing data: ['country'] \n",
      "\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      "\n",
      "hotel : \n",
      "is_canceled : \n",
      "\t  credit_card :  60.67\n",
      "\t  month :  39.33\n",
      "lead_time : \n",
      "\t  credit_card :  14.67\n",
      "\t  month :  11.67\n",
      "arrival_date_year : \n",
      "arrival_date_month : \n",
      "\t  city :  8.0\n",
      "\t  month :  100.0\n",
      "arrival_date_week_number : \n",
      "\t  credit_card :  9.0\n",
      "\t  month :  15.67\n",
      "arrival_date_day_of_month : \n",
      "\t  credit_card :  5.67\n",
      "\t  month :  43.33\n",
      "stays_in_weekend_nights : \n",
      "\t  credit_card :  46.0\n",
      "\t  month :  54.0\n",
      "stays_in_week_nights : \n",
      "\t  credit_card :  3.33\n",
      "\t  month :  96.67\n",
      "adults : \n",
      "\t  credit_card :  0.33\n",
      "\t  month :  99.67\n",
      "children : \n",
      "babies : \n",
      "\t  credit_card :  100.0\n",
      "meal : \n",
      "\t  state :  7.0\n",
      "\t  country :  87.0\n",
      "country : \n",
      "\t  city :  1.33\n",
      "\t  country :  99.67\n",
      "market_segment : \n",
      "distribution_channel : \n",
      "is_repeated_guest : \n",
      "\t  credit_card :  97.0\n",
      "\t  month :  3.0\n",
      "previous_cancellations : \n",
      "\t  credit_card :  96.33\n",
      "\t  month :  3.33\n",
      "previous_bookings_not_canceled : \n",
      "\t  credit_card :  97.0\n",
      "\t  month :  2.67\n",
      "reserved_room_type : \n",
      "assigned_room_type : \n",
      "booking_changes : \n",
      "\t  credit_card :  86.33\n",
      "\t  month :  13.67\n",
      "deposit_type : \n",
      "agent : \n",
      "company : \n",
      "days_in_waiting_list : \n",
      "\t  credit_card :  96.67\n",
      "\t  month :  0.33\n",
      "customer_type : \n",
      "adr : \n",
      "required_car_parking_spaces : \n",
      "\t  credit_card :  95.0\n",
      "\t  month :  5.0\n",
      "total_of_special_requests : \n",
      "\t  credit_card :  61.67\n",
      "\t  month :  38.33\n",
      "reservation_status : \n",
      "reservation_status_date : \n",
      "\t  date :  100.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for key in lst:\n",
    "    print('----------------------',os.path.basename(key),'----------------------')\n",
    "    print('DATA SUMMARY:\\n')\n",
    "    eda(lst[key])\n",
    "    cscore(lst[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_numeric(data):\n",
    "    rw = data.shape[0]\n",
    "    print('Rows: ',str(rw))\n",
    "    print('Columns: ',str(data.shape[1]),'\\n')\n",
    "    pk = []\n",
    "    mis = []\n",
    "    for col in data:\n",
    "        try:\n",
    "            pd.to_numeric(data[col])\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "        print(col,':-')\n",
    "        u = data[col].nunique()\n",
    "        print('Unique Value Count:',u)\n",
    "        if u == rw:\n",
    "            pk.append(col)\n",
    "        n = data[col].size - data[col].count()\n",
    "        print('Null Count:',n)\n",
    "        if n != 0:\n",
    "            mis.append(col)\n",
    "        freq = data[col].value_counts()\n",
    "        print('Top Three Frequency Values:')\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                val = freq[i]\n",
    "            except:\n",
    "                break\n",
    "            if val == 1:\n",
    "                if i == 0:\n",
    "                    print('N/A')\n",
    "                break\n",
    "            print('\\t',freq.keys()[i],':',val) \n",
    "        print('')\n",
    "    print ('Possible Primary Key(s):',pk)\n",
    "    print ('Columns with missing data:',mis,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
