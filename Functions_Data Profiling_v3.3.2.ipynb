{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports U.S county names. \n",
    "Input name should have county tag at the end (example Tippecanoe county, clay county). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "import fnmatch\n",
    "gc = geonamescache.GeonamesCache()\n",
    "co = gc.get_us_counties()\n",
    "counties = []\n",
    "for i in co:\n",
    "    counties.append(i['name'].upper())\n",
    "    if i['name'].find(' County') != -1:\n",
    "        counties.append(i['name'].replace(' County','').upper())\n",
    "\n",
    "def county_chk(strn):\n",
    "    '''Function to detect the validity of the county name. Uses geonamescache library'''\n",
    "    if strn.upper() not in counties:\n",
    "        return 'Not valid'\n",
    "    else:\n",
    "        return 'Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2.Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports city names across the globe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "c = gc.get_cities()\n",
    "cities = [c[key]['name'] for key in list(c.keys())]\n",
    "cities = list(map(lambda x:x.upper(), cities))\n",
    "cities = [x for x in cities if str(x) != 'NAN']\n",
    "\n",
    "def city_chk(strn):\n",
    "    '''Function to detect the validity of the city name. Uses geonamescache library'''\n",
    "    if strn.upper() in cities:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports U.S state names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "st = gc.get_us_states()\n",
    "stcode = []\n",
    "states = []\n",
    "for i in st:\n",
    "    stcode.append(st[i]['code'])\n",
    "    states.append(st[i]['name'].upper())\n",
    "\n",
    "def state_chk(strn):\n",
    "    '''Function to detect the validity of the state name. Uses geonamescache library'''\n",
    "    chk = 0\n",
    "    if strn.upper() in states or strn.upper() in stcode:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid for both upper case and lower case. Supports country names across the globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "cntrs = list(pycountry.countries)\n",
    "c_name = []\n",
    "official_name = []\n",
    "alpha_2 = []\n",
    "alpha_3 = []\n",
    "for i in cntrs:\n",
    "    c_name.append(i.name.upper())\n",
    "    if i.name.find(',')!=-1:\n",
    "        c_name.append((i.name[i.name.find(',')+2:]+' '+i.name[:i.name.find(',')]).upper())\n",
    "        for j in ('IRAN','RUSSIA','SOUTH KOREA','VIETNAM','BOLIVIA','TAIWAN','UK','SYRIA','VENEZUELA'):\n",
    "            c_name.append(j)\n",
    "    try:\n",
    "        official_name.append(i.official_name.upper())\n",
    "    except:\n",
    "        pass\n",
    "    alpha_2.append(i.alpha_2)\n",
    "    alpha_3.append(i.alpha_3)\n",
    "    \n",
    "\n",
    "def country_chk(strn):\n",
    "    '''Function to detect the validity of the country name. Uses pycountry library'''\n",
    "    chk = 0\n",
    "    if strn.upper() in c_name or strn.upper() in official_name or strn.upper() in alpha_2 or strn.upper() in alpha_3:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Currency_US Dollar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satisfying Conditions:\n",
    "\n",
    "1. Format: Currency(space optional)NNNN.DD(upto 2 decimals)\n",
    "2. Currency : USD|usd|EUR|EURO|euro|eur|£|JPY|¥|CNY|GBP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_chk(amount):\n",
    "    '''Function to detect the validity of the US Cuurency. Uses regex library'''\n",
    "    import re\n",
    "    regex = re.compile(r'^(\\$|USD|usd|EUR|EURO|euro|eur|£|JPY|¥|CNY|GBP)\\s?(\\d*(\\d\\.?|\\.\\d{1,2}))$')\n",
    "    result = regex.match(amount)\n",
    "    if result:\n",
    "        return('Valid')\n",
    "    else:\n",
    "        return('Not Valid')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Phone Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supports following formats\n",
    "1. 000-000-0000\n",
    "2. 000 000 0000\n",
    "3. 000.000.0000\n",
    "4. (000)0000000\n",
    "5. 000-0000\n",
    "6. 000 0000\n",
    "7. 000.0000\n",
    "8. 0000000\n",
    "9. 0000000000\n",
    "\n",
    "Maximum of 12 digits is allowed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_chk(number):\n",
    "    '''Function to detect the phone numbers in US. Supports home/landline phone numbers and mobile numbers.\n",
    "        Uses regex library'''\n",
    "    if len(number)<=12 and len(number)>=6:\n",
    "        import re\n",
    "        regex=re.compile(r'^\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}')\n",
    "        result = regex.match(number)\n",
    "        if result:\n",
    "            return 'Valid'\n",
    "        else:\n",
    "            return 'Not Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Credit Card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Luhn Algorithm to detct the credit card detections\n",
    "\n",
    " https://en.wikipedia.org/wiki/Payment_card_number\n",
    " \n",
    " https://en.wikipedia.org/wiki/Luhn_algorithm\n",
    " \n",
    " https://www.geeksforgeeks.org/luhn-algorithm/\n",
    " \n",
    " Number of digits allowed : 13-19\n",
    "        \n",
    "Working Credit Cards under this Algo: \n",
    "1. AMEX\n",
    "2. Bankcard\n",
    "3. Diners Club enRoue\n",
    "4. Discover Card\n",
    "5. RuPay\n",
    "6. InterPayment\n",
    "7. JCB\n",
    "8. Laser\n",
    "9. Maestro\n",
    "10. Dankort\n",
    "11. MIR\n",
    "12. NPS Pridnestrovie\n",
    "13. Mastercard\n",
    "14. Solo\n",
    "15. Switch\n",
    "16. Troy\n",
    "17. Visa\n",
    "18. UATP\n",
    "19. Verve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_chk(card_number):\n",
    "    '''Function to detect whether credit card is valid or not by its card number. Dev. by using Luhn algo'''\n",
    "    if len(card_number)>=13 and len(card_number)<=19:\n",
    "        try:\n",
    "            cc_list=[int(d) for d in str(card_number)]\n",
    "            odd_digits = cc_list[-1::-2]\n",
    "            #print(odd_digits)\n",
    "            even_digits = cc_list[-2::-2]\n",
    "            #print(even_digits)\n",
    "            cc_digits_sum = 0\n",
    "            cc_digits_sum += sum(odd_digits)\n",
    "            for d in even_digits:\n",
    "                d*=2\n",
    "                if d > 9:\n",
    "                    d= d-9 \n",
    "                cc_digits_sum=cc_digits_sum + d\n",
    "            if cc_digits_sum % 10==0:\n",
    "                return 'Valid'\n",
    "            else:\n",
    "                return 'Not Valid'\n",
    "        except:\n",
    "            return 'Not Valid'\n",
    "    else:\n",
    "        return 'Not Valid'\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Mail ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mail ID starting character should be aplhamnumeric. \n",
    "Should have 2 or 3 characters at the end after '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_chk(val):\n",
    "    \n",
    "    '''Function to detect the validity email. Uses regex library'''\n",
    "    import re\n",
    "    regex = '^\\w+([\\.-]?\\w+)*@\\w+([\\.-]?\\w+)*(\\.\\w{2,3})+$'\n",
    "    c=0\n",
    "    if(re.search(regex,val)):  \n",
    "         return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL should start with http:// or https://, can have any alphanumeric domain name and must end with two or more characters after the '.'\n",
    "It also incorporates URLs with IP or server addresses like \"http://localhost:8889/notebooks/Functions_Data%20Profiling.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_chk(val):\n",
    "    \n",
    "    '''Function to detect the validity email. Uses regex library'''\n",
    "    import re\n",
    "    a=0\n",
    "    regex = re.compile(\n",
    "            r'^(?:http|ftp)s?://' # http:// or https://\n",
    "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "            r'localhost|' #localhost...\n",
    "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "            r'(?::\\d+)?' # optional port\n",
    "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "\n",
    "    if (re.match(regex, val) is not None) == True:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Works with Jan, jan, January, 01, 1 formats. \n",
    "2. If the input is using correct word for the month, irrespective of the lower, upper cases it will read ( Jan, JAn, jANUaRy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=['jan','january','feb','february','mar','march','apr','april','may','jun','june','jul','july','aug','august','sep','september','oct','october','nov','november','dec','december']\n",
    "def month_chk(string):\n",
    "    import re\n",
    "    string=string.lower()\n",
    "    if string in month:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works with\n",
    "1. Positive and negative sign for the temperature\n",
    "2. After decimal 2 digits only\n",
    "3. Temperature symbol can be [CcFf]\n",
    "4. Space or no-space between ineteger and the temp (CcFf) symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_chk(string):\n",
    "    import re\n",
    "    regex=re.compile(r\"([+-]?((\\d*(\\d\\.?|\\.\\d{1,2}))\\s?°?(?i)(\\W|^)(C|c|F|F)(\\W|$)))\")\n",
    "    result=regex.match(string)\n",
    "    if result:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_chk(string):\n",
    "    import re\n",
    "    regex=re.compile(r\"((\\d*(\\d\\.?|\\.\\d{1,2}))\\s?(?i)(\\W|^)(KMS|km|miles|mile|INCH|M|feet|ft)(\\W|$))\")\n",
    "    result=regex.match(string)\n",
    "    if result:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def date_chk(date_time_str):\n",
    "    chk = 0\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y-%m-%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y-%d-%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y-%d-%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y/%m/%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y/%m/%d')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%Y/%d/%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%y/%d/%m')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m-%d-%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m-%d-%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d-%m-%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d-%m-%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m/%d/%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%m/%d/%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d/%m/%Y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%d/%m/%y')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if chk == 1:\n",
    "        return 'Valid'\n",
    "\n",
    "    else:\n",
    "        return 'Not Valid'\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_chk(date_time_str):\n",
    "    chk = 0\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%H:%M')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%H:%M:%S')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_time_str, '%H:%M:%S.%f')\n",
    "        chk = 1\n",
    "    except:\n",
    "        pass\n",
    "    if chk == 1:\n",
    "        return 'Valid'\n",
    "\n",
    "    else:\n",
    "        return 'Not Valid'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "target_url = \"https://gist.githubusercontent.com/atduskgreg/3cf8ef48cb0d29cf151bedad81553a54/raw/82f142562cf50b0f6fb8010f890b2f934093553e/animals.txt\"\n",
    "animals = list()\n",
    "for line in urllib.request.urlopen(target_url):\n",
    "        animals.append(line.decode('utf-8')[:-1].lower())\n",
    "def animal_chk(string):\n",
    "    if string.lower() in animals:\n",
    "        return 'Valid'\n",
    "    else:\n",
    "        return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_chk(string):\n",
    "    test = nlp(string.lower())\n",
    "    for X in test:\n",
    "        if X.ent_type_=='PERSON':\n",
    "            return 'Valid'\n",
    "    return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_chk(string):\n",
    "    if string.lower() in ['male','female']:\n",
    "        return 'Valid'\n",
    "    if string.lower() in ['m','f']:\n",
    "        return 'Valid'\n",
    "    return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_chk(string):\n",
    "    try:\n",
    "        if int(string) in [1,0]:\n",
    "            return 'Valid'\n",
    "    except:\n",
    "        pass\n",
    "    if string.lower() in ['true','false']:\n",
    "        return 'Valid'\n",
    "    if string.lower() in ['t','f']:\n",
    "        return 'Valid'\n",
    "    return 'Not Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data input is csv file path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grph(data):\n",
    "    data_1=pd.read_csv(data)\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    col_num=[]\n",
    "    col_str=[]\n",
    "    for col in data_1:\n",
    "        try:\n",
    "            pd.to_numeric(data_1[col])\n",
    "            col_num.append(col)\n",
    "        except:\n",
    "            col_str.append(col)\n",
    "    y=len(col_num)\n",
    "    x=(y//2)+1 \n",
    "    with PdfPages('Numeric EDA.pdf') as pdf:\n",
    "        plt.figure(figsize=(4*x,5*x))\n",
    "        for i in range(1,y+1):\n",
    "            plt.subplot(x,2,i,facecolor=(1,1,1))\n",
    "            plt.grid(False)\n",
    "            #print(data[col_num[i-1]])\n",
    "            plt.hist(data_1[col_num[i-1]],bins=10,color=\"lightseagreen\")\n",
    "            plt.title(col_num[i-1], fontsize=20)\n",
    "            #plt.text(0.5,0.5,print('Mean', data[col_num[i-1]].mean()))\n",
    "            plt.suptitle('Numeric EDA',fontsize=25)\n",
    "        pdf.savefig()  # saves the current figure into a pdf page\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the csv file, checking the column characteristic and assigning the accuracy score:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the FileS List: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "#path =r'C:\\Users\\rahul\\OneDrive\\Desktop\\Samtec\\\\' # use your path, replace the last backslash with filename to run for a single file\n",
    "path=\"/Users/sagarkurada/Documents/Courses/Spring-3/Data Profiling/Test/\"\n",
    "csv = glob.glob(path + \"*.csv\")\n",
    "\n",
    "lst = dict()\n",
    "\n",
    "for filename in csv:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    lst[filename] = df\n",
    "\n",
    "#print(lst)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data):\n",
    "    '''Random sampling of data'''\n",
    "    if data.shape[0] > 999:\n",
    "        return data.sample(frac=0.3, random_state=1)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of entity columns to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "funclist = [county_chk,city_chk,state_chk,country_chk,currency_chk,phone_chk,credit_card_chk,email_chk,url_chk,date_chk,time_chk,distance_chk,temperature_chk,month_chk,animal_chk,name_chk,gender_chk,binary_chk]\n",
    "funclist_num = [phone_chk,credit_card_chk,binary_chk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Score Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cscore(data):\n",
    "    '''Function to calculate the confidence score for each column'''\n",
    "    import random\n",
    "    print('\\nCONFIDENCE SCORES:\\n ')\n",
    "    data = sample(data)\n",
    "    data_dict = data.to_dict()\n",
    "    from prettytable import PrettyTable\n",
    "    x = PrettyTable()\n",
    "    x.field_names = [\"Column Name\", \"Tested Entity\", \"Confidence Score\"]\n",
    "    \n",
    "    for i in data_dict.keys():\n",
    "        #print(i,': ')\n",
    "        u = data[i].nunique()\n",
    "        try:\n",
    "            pd.to_numeric(data[i])\n",
    "            func = funclist_num\n",
    "        except:\n",
    "            func = funclist\n",
    "        for j in func:\n",
    "            #start=0\n",
    "            #end=0\n",
    "            #start = timeit.timeit()\n",
    "            func_str = str(j)[10:str(j).find('at ')-5]\n",
    "            if func_str == 'name' and len(data_dict[i].items())>300:\n",
    "                d2 = dict((k,j(str(v))) for k, v in random.sample(data_dict[i].items(),k=300))\n",
    "            else:    \n",
    "                d2 = dict((k,j(str(v))) for k, v in data_dict[i].items())\n",
    "            d3= {k:(1 if v=='Valid' else 0 ) for (k,v) in d2.items()}\n",
    "            a=[v for v in d3.values()]\n",
    "            accuracy=round((sum(a)/len(a))*100,2)\n",
    "            #end = timeit.timeit()\n",
    "            #print(str(j),(end - start))\n",
    "            if func_str == 'binary' and u!=2:\n",
    "                accuracy = 0\n",
    "            if accuracy != 0:\n",
    "                l=[]\n",
    "                l.append(str(i))\n",
    "                #print('1',l)\n",
    "                l.append(str(j)[9:str(j).find('at ')-5])\n",
    "                l.append(str(accuracy))\n",
    "                #print('2',l)\n",
    "                x.add_row(l)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(data):\n",
    "    rw = data.shape[0]\n",
    "    print('Rows: ',str(rw))\n",
    "    print('Columns: ',str(data.shape[1]),'\\n')\n",
    "    pk = []\n",
    "    mis = []\n",
    "    from prettytable import PrettyTable\n",
    "    #y = PrettyTable()\n",
    "    #y.field_names = [\"Value\", \"Count\"]\n",
    "    for col in data:\n",
    "        try:\n",
    "            pd.to_numeric(data[col])\n",
    "            print('Mean', data[col].mean())\n",
    "            print('Median',data[col].median())\n",
    "            \n",
    "            plt.style.use('ggplot')\n",
    "            plt.hist(data[col], bins=10)\n",
    "            plt.show()\n",
    "            print('\\n')\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "        print('Column Name:',col)\n",
    "        #print('\\n')\n",
    "        u = data[col].nunique()\n",
    "        print('Unique Value Count:',u)\n",
    "        if u == rw:\n",
    "            pk.append(col)\n",
    "        n = data[col].size - data[col].count()\n",
    "        print('Null Count:',n)\n",
    "        if n != 0:\n",
    "            mis.append(col)\n",
    "        freq = data[col].value_counts()\n",
    "        print('Top Three Frequency Values:')\n",
    "        y = PrettyTable()\n",
    "        y.field_names = [\"Value\", \"Count\"]\n",
    "        for i in range(3):\n",
    "            t3f=[]\n",
    "            try:\n",
    "                val = freq[i]\n",
    "            except:\n",
    "                break\n",
    "            if val == 1:\n",
    "                if i == 0:\n",
    "                    print('N/A')\n",
    "                break\n",
    "\n",
    "            t3f.append(freq.keys()[i])\n",
    "            t3f.append(val)\n",
    "            y.add_row(t3f)\n",
    "        print(y)\n",
    "        print('\\n')\n",
    "    print ('Possible Primary Key(s):',pk)\n",
    "    print ('Columns with missing data:',mis,'\\n')\n",
    "    print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------- data.csv ----------------------\n",
      "DATA SUMMARY:\n",
      "\n",
      "Rows:  306\n",
      "Columns:  8 \n",
      "\n",
      "Column Name: Country\n",
      "Unique Value Count: 68\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+-----------+-------+\n",
      "|   Value   | Count |\n",
      "+-----------+-------+\n",
      "|   China   |   74  |\n",
      "|   India   |   19  |\n",
      "| Indonesia |   12  |\n",
      "+-----------+-------+\n",
      "\n",
      "\n",
      "Column Name: State\n",
      "Unique Value Count: 52\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+---------+-------+\n",
      "|  Value  | Count |\n",
      "+---------+-------+\n",
      "|  Nevada |   5   |\n",
      "| Alabama |   5   |\n",
      "| Florida |   5   |\n",
      "+---------+-------+\n",
      "\n",
      "\n",
      "Column Name: City\n",
      "Unique Value Count: 247\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+-----------+-------+\n",
      "|   Value   | Count |\n",
      "+-----------+-------+\n",
      "|  BUDAPEST |   2   |\n",
      "|  Semarang |   2   |\n",
      "| Hyderabad |   2   |\n",
      "+-----------+-------+\n",
      "\n",
      "\n",
      "Column Name: County\n",
      "Unique Value Count: 230\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+--------+-------+\n",
      "| Value  | Count |\n",
      "+--------+-------+\n",
      "| Marion |   2   |\n",
      "|  Clay  |   2   |\n",
      "|  Lee   |   2   |\n",
      "+--------+-------+\n",
      "\n",
      "\n",
      "Column Name: Phone Number\n",
      "Unique Value Count: 120\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+--------------+-------+\n",
      "|    Value     | Count |\n",
      "+--------------+-------+\n",
      "| 916-712-5188 |   3   |\n",
      "| 956-285-0365 |   3   |\n",
      "| 914-920-7170 |   3   |\n",
      "+--------------+-------+\n",
      "\n",
      "\n",
      "Column Name: Email ID\n",
      "Unique Value Count: 248\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+-----------------+-------+\n",
      "|      Value      | Count |\n",
      "+-----------------+-------+\n",
      "|  ozawa@mac.com  |   2   |\n",
      "| aracne@yahoo.ca |   2   |\n",
      "+-----------------+-------+\n",
      "\n",
      "\n",
      "Column Name: URL\n",
      "Unique Value Count: 181\n",
      "Null Count: 56\n",
      "Top Three Frequency Values:\n",
      "+--------------------------+-------+\n",
      "|          Value           | Count |\n",
      "+--------------------------+-------+\n",
      "| https://www.example.com/ |   15  |\n",
      "| http://www.example.com/  |   15  |\n",
      "|   https://example.com/   |   13  |\n",
      "+--------------------------+-------+\n",
      "\n",
      "\n",
      "Possible Primary Key(s): []\n",
      "Columns with missing data: ['Country', 'State', 'City', 'County', 'Phone Number', 'Email ID', 'URL'] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      " \n",
      "+--------------+---------------+------------------+\n",
      "| Column Name  | Tested Entity | Confidence Score |\n",
      "+--------------+---------------+------------------+\n",
      "|   Country    |      city     |       4.25       |\n",
      "|   Country    |      state    |       0.33       |\n",
      "|   Country    |     country   |      80.39       |\n",
      "|   Country    |     animal    |       1.31       |\n",
      "|   Country    |      name     |       0.67       |\n",
      "|    State     |     county    |       28.1       |\n",
      "|    State     |      city     |       13.4       |\n",
      "|    State     |      state    |      80.39       |\n",
      "|    State     |     country   |       2.94       |\n",
      "|     City     |     county    |       2.29       |\n",
      "|     City     |      city     |      66.01       |\n",
      "|     City     |      state    |       0.33       |\n",
      "|     City     |     country   |       0.33       |\n",
      "|     City     |      name     |       5.67       |\n",
      "|    County    |     county    |      80.39       |\n",
      "|    County    |      city     |      30.07       |\n",
      "|    County    |      state    |       1.96       |\n",
      "|    County    |     animal    |       0.65       |\n",
      "|    County    |      name     |       8.33       |\n",
      "| Phone Number |      phone    |       81.7       |\n",
      "|   Email ID   |      email    |       81.7       |\n",
      "|     URL      |       url     |       81.7       |\n",
      "|     URL      |      name     |       0.33       |\n",
      "+--------------+---------------+------------------+\n",
      "\n",
      "\n",
      "---------------------- animals.csv ----------------------\n",
      "DATA SUMMARY:\n",
      "\n",
      "Rows:  520\n",
      "Columns:  1 \n",
      "\n",
      "Column Name: Canidae\n",
      "Unique Value Count: 472\n",
      "Null Count: 0\n",
      "Top Three Frequency Values:\n",
      "+------------+-------+\n",
      "|   Value    | Count |\n",
      "+------------+-------+\n",
      "|    list    |   24  |\n",
      "|   Horse    |   3   |\n",
      "| Guinea pig |   3   |\n",
      "+------------+-------+\n",
      "\n",
      "\n",
      "Possible Primary Key(s): []\n",
      "Columns with missing data: [] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      " \n",
      "+-------------+---------------+------------------+\n",
      "| Column Name | Tested Entity | Confidence Score |\n",
      "+-------------+---------------+------------------+\n",
      "|   Canidae   |     county    |       2.31       |\n",
      "|   Canidae   |      city     |       0.96       |\n",
      "|   Canidae   |     country   |       0.38       |\n",
      "|   Canidae   |     animal    |      100.0       |\n",
      "|   Canidae   |      name     |       5.33       |\n",
      "+-------------+---------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for key in lst:\n",
    "    print('\\n')\n",
    "    print('----------------------',os.path.basename(key),'----------------------')\n",
    "    print('DATA SUMMARY:\\n')\n",
    "    eda(lst[key])\n",
    "    cscore(lst[key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
